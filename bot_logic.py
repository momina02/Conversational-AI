import webrtcvad
import pyaudio
import wave
import whisper
from groq import Groq
import edge_tts
import asyncio
import os
from dotenv import load_dotenv
from pydub import AudioSegment
from pydub.playback import play

load_dotenv()

FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 480
VAD_MODE = 2

def record_audio():
    vad = webrtcvad.Vad(VAD_MODE)
    pa = pyaudio.PyAudio()
    stream = pa.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)

    frames = []
    silence_counter = 0
    silence_threshold = 15
    min_speech_chunks = 10

    print("ğŸ™ï¸ Ø³Ù†Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø± ÛÙˆÚº...")

    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        is_speech = vad.is_speech(data, RATE)
        print(f"{'ğŸ”Š Ø¨ÙˆÙ„ Ø±ÛÛ’ ÛÛŒÚº' if is_speech else 'ğŸ¤« Ø®Ø§Ù…ÙˆØ´ÛŒ'}")

        if is_speech:
            frames.append(data)
            silence_counter = 0
        else:
            if len(frames) >= min_speech_chunks:
                silence_counter += 1
                if silence_counter >= silence_threshold:
                    break

    stream.stop_stream()
    stream.close()
    pa.terminate()

    filename = "input.wav"
    wf = wave.open(filename, "wb")
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(pa.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()

    return filename

def transcribe_audio(audio_file):
    try:
        model = whisper.load_model("base")
        result = model.transcribe(audio_file, language="ur")
        return result["text"]
    except Exception as e:
        print(f"âš ï¸ Transcription error: {e}")
        return ""

def generate_response(text):
    try:
        client = Groq(api_key=os.getenv("GROQ_API_KEY"))
        chat_completion = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "Ø¢Ù¾ Ø§Ø±Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ú©Û’ Ù…Ø§ÛØ± Ø§Ø³ØªØ§Ø¯ ÛÛŒÚºÛ” Ø¢Ù¾ ØµØ±Ù Ø§Ø±Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ù…ÛŒÚº Ú¯Ø±Ø§Ù…Ø±ØŒ ØªÙ„ÙØ¸ØŒ Ù„ØºØªØŒ Ø§ÙˆØ± Ø¬Ù…Ù„ÙˆÚº Ú©ÛŒ Ø³Ø§Ø®Øª Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº Ø³Ø§Ø¯Û Ø§ÙˆØ± ÙˆØ§Ø¶Ø­ Ø§Ù†Ø¯Ø§Ø² Ù…ÛŒÚº ØªØ¹Ù„ÛŒÙ… Ø¯ÛŒØªÛ’ ÛÛŒÚºÛ” Ø¢Ù¾ Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ ÛŒØ§ Ú©Ø³ÛŒ Ø¨Ú¾ÛŒ ØºÛŒØ± Ø§Ø±Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ú©Ø§ Ú©ÙˆØ¦ÛŒ Ù„ÙØ¸ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ù†ÛÛŒÚº Ú©Ø±ØªÛ’Û” Ø§Ú¯Ø± ØµØ§Ø±Ù Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ Ù…ÛŒÚº Ø³ÙˆØ§Ù„ Ú©Ø±Û’ ØªÙˆ Ø¢Ù¾ Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº ÛÛŒ Ø¬ÙˆØ§Ø¨ Ø¯ÛŒÚº Ú¯Û’ Ø§ÙˆØ± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø±ÛŒÚº Ú¯Û’ Ú©Û ÙˆÛ Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ø¨Ø§Øª Ú©Ø±ÛŒÚºÛ” Ø¢Ù¾ ÛØ± Ø³ÙˆØ§Ù„ Ú©Ø§ Ø¬ÙˆØ§Ø¨ Ø§Ø±Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ù…ÛŒÚº Ø¯ÛŒÚº Ú¯Û’ØŒ Ú†Ø§ÛÛ’ Ø³ÙˆØ§Ù„ Ú©Ø³ÛŒ Ø¨Ú¾ÛŒ Ø²Ø¨Ø§Ù† Ù…ÛŒÚº ÛÙˆÛ”"},
                {"role": "user", "content": text}
            ],
            model="meta-llama/llama-4-scout-17b-16e-instruct",
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        print(f"âš ï¸ Groq error: {e}")
        return ""

async def text_to_speech(text):
    try:
        output_file = "output.mp3"
        communicate = edge_tts.Communicate(text, "ur-PK-AsadNeural")
        await communicate.save(output_file)
        return output_file
    except Exception as e:
        print(f"âš ï¸ TTS Error: {e}")
        return ""

def play_audio(audio_file):
    try:
        if os.path.exists(audio_file):
            audio = AudioSegment.from_mp3(audio_file)
            play(audio)
    except Exception as e:
        print(f"âš ï¸ Play error: {e}")
